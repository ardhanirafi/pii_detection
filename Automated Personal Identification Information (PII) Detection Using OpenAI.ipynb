{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membaca file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membaca file CSV\n",
    "df_datakaryawan = pd.read_csv(\"csv datasets/data_karyawan.csv\")\n",
    "df_datacustomer = pd.read_csv(\"csv datasets/data_customer.csv\")\n",
    "df_alamatcust = pd.read_csv(\"csv datasets/alamat_customer.csv\")\n",
    "df_browsing = pd.read_csv(\"csv datasets/browsing_history.csv\")\n",
    "df_custpurchase = pd.read_csv(\"csv datasets/customer_purchase.csv\")\n",
    "df_custpulsa = pd.read_csv(\"csv datasets/customer_isipulsa.csv\")\n",
    "df_tagihan = pd.read_csv(\"csv datasets/tagihan_pelanggan.csv\")\n",
    "df_reportsales = pd.read_csv(\"csv datasets/report_sales.csv\")\n",
    "df_productcatalog = pd.read_csv(\"csv datasets/product_catalog.csv\")\n",
    "df_device = pd.read_csv(\"csv datasets/telkomsel_device_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menampilkan info dan 5 baris pertama dari semua dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Karyawan ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Employee ID            17 non-null     float64\n",
      " 1   Employee Name          20 non-null     object \n",
      " 2   Employee Email         20 non-null     object \n",
      " 3   Employee Phone Number  16 non-null     object \n",
      " 4   Position               20 non-null     object \n",
      " 5   Department             20 non-null     object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 1.1+ KB\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "   Employee ID         Employee Name                Employee Email  \\\n",
      "0       8893.0        Shannon Curtis              iallen@gmail.com   \n",
      "1       2006.0      Michelle Clayton        smithshelley@gmail.com   \n",
      "2          NaN  Michael Stevenson MD  gutierrezvictor@higgins.info   \n",
      "3       2596.0       Elizabeth Young          batesjames@gmail.com   \n",
      "4       2784.0            Penny Rose   ballmegan@becker-knight.com   \n",
      "\n",
      "  Employee Phone Number              Position                 Department  \n",
      "0                   apa          Photographer  Hansen, Nichols and Perez  \n",
      "1           85632109876  Electronics engineer                 Powell LLC  \n",
      "2           87843215678           Fine artist                 Macias LLC  \n",
      "3                   NaN   Retail merchandiser     Buck, Casey and Nelson  \n",
      "4           81354679852      Health physicist       Ward, Evans and Chen  \n",
      "\n",
      "\n",
      "=== Data Customer ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Customer ID            16 non-null     object \n",
      " 1   Customer Name          16 non-null     object \n",
      " 2   Customer Email         20 non-null     object \n",
      " 3   Customer Phone Number  13 non-null     float64\n",
      " 4   Date of Birth          20 non-null     object \n",
      " 5   Gender                 20 non-null     object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 1.1+ KB\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Customer ID    Customer Name           Customer Email  \\\n",
      "0        1737  Alicia Crawford    michael05@hotmail.com   \n",
      "1        1312       Diana Hood         gduffy@yahoo.com   \n",
      "2         NaN   Steven Andrade    robertlewis@burns.com   \n",
      "3        3484              NaN      william25@gmail.com   \n",
      "4         apa       Gary Bryan  clarkmichelle@gmail.com   \n",
      "\n",
      "   Customer Phone Number Date of Birth  Gender  \n",
      "0           8.171235e+10    1986-07-22    Male  \n",
      "1                    NaN    1993-06-24  Female  \n",
      "2           8.394322e+10    1957-11-24  Female  \n",
      "3                    NaN    2000-07-11  Female  \n",
      "4           8.518766e+10    1949-07-01    Male  \n",
      "\n",
      "\n",
      "=== Alamat Customer ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Customer ID     16 non-null     object \n",
      " 1   Address Line 1  16 non-null     object \n",
      " 2   Address Line 2  16 non-null     object \n",
      " 3   City            17 non-null     object \n",
      " 4   State           20 non-null     object \n",
      " 5   Postal Code     14 non-null     float64\n",
      " 6   Country         17 non-null     object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 1.2+ KB\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Customer ID                 Address Line 1 Address Line 2  \\\n",
      "0         NaN  400 Clayton Turnpike Apt. 428       Apt. 417   \n",
      "1        6929                            NaN       Apt. 113   \n",
      "2         apa    828 Laura Crossing Apt. 672      Suite 194   \n",
      "3        7408                            NaN       Apt. 414   \n",
      "4        6176               450 Villegas Way      Suite 690   \n",
      "\n",
      "                City     State  Postal Code                  Country  \n",
      "0    New Anthonyfort  Maryland      93357.0                    34245  \n",
      "1          Port Erik   Indiana      99083.0                  Algeria  \n",
      "2  North Adamborough  Delaware          NaN  Cocos (Keeling) Islands  \n",
      "3         Wrightside      2345      58867.0                  Andorra  \n",
      "4          Dixonview  Colorado      11753.0                  Morocco  \n",
      "\n",
      "\n",
      "=== Browsing History ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 4 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Customer Browsing History ID  18 non-null     object\n",
      " 1   URL                           18 non-null     object\n",
      " 2   Timestamp                     17 non-null     object\n",
      " 3   Duration (seconds)            19 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 772.0+ bytes\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Customer Browsing History ID                       URL            Timestamp  \\\n",
      "0                         8005   http://www.alvarez.org/  2024-05-31 13:51:26   \n",
      "1                         9110        https://clark.com/  2024-02-18 11:16:14   \n",
      "2                          NaN                     43563  2024-04-22 05:50:41   \n",
      "3                         5800  https://www.burgess.com/  2024-05-30 03:12:12   \n",
      "4                         6475                       NaN  2024-05-05 04:33:08   \n",
      "\n",
      "  Duration (seconds)  \n",
      "0               3071  \n",
      "1                720  \n",
      "2                591  \n",
      "3               3072  \n",
      "4               2927  \n",
      "\n",
      "\n",
      "=== Customer Purchase ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Customer Purchase ID  15 non-null     object\n",
      " 1   Product ID            16 non-null     object\n",
      " 2   Purchase Date         20 non-null     object\n",
      " 3   Quantity              20 non-null     int64 \n",
      " 4   Price                 20 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 932.0+ bytes\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Customer Purchase ID Product ID Purchase Date  Quantity  Price\n",
      "0                  NaN        454    2024-05-26         2    541\n",
      "1                 7415        661    2024-04-09         7     36\n",
      "2                 1083        467    2024-02-04         9    369\n",
      "3                  NaN        836    2024-03-24         5    638\n",
      "4                 2670        asa    2024-01-25         1    520\n",
      "\n",
      "\n",
      "=== Customer Pulsa ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Customer Pulsa ID       17 non-null     object\n",
      " 1   Phone Number Isi Pulsa  17 non-null     object\n",
      " 2   Date                    20 non-null     object\n",
      " 3   Amount                  16 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 772.0+ bytes\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Customer Pulsa ID Phone Number Isi Pulsa        Date Amount\n",
      "0              3102                    NaN  2023-01-01  37576\n",
      "1              1334           623284728221  2023-01-02    NaN\n",
      "2               NaN           624670916237  2023-01-03  68719\n",
      "3              5129           623814446967  2023-01-04   6759\n",
      "4              2759                    NaN  2023-01-05  14182\n",
      "\n",
      "\n",
      "=== Tagihan Pelanggan ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Tagihan Customer ID  16 non-null     object\n",
      " 1   Invoice ID           17 non-null     object\n",
      " 2   Invoice Date         18 non-null     object\n",
      " 3   Due Date             18 non-null     object\n",
      " 4   Amount               19 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 932.0+ bytes\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Tagihan Customer ID Invoice ID Invoice Date    Due Date Amount\n",
      "0                8557       2624   2024-04-12  2024-04-26   1859\n",
      "1                 NaN       6225   2024-04-05  2024-02-29    495\n",
      "2                 has       4536   2024-05-20  2024-01-10    698\n",
      "3                2386       5348          NaN  2024-04-07   dsad\n",
      "4                5863       ngds   2024-06-03  2024-01-22   3281\n",
      "\n",
      "\n",
      "=== Sales Report ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Agent ID      16 non-null     object \n",
      " 1   Agent Name    18 non-null     object \n",
      " 2   Sales Region  20 non-null     object \n",
      " 3   Total Sales   18 non-null     float64\n",
      " 4   Date          20 non-null     object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 932.0+ bytes\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Agent ID Agent Name Sales Region  Total Sales        Date\n",
      "0     4652    Agent_1         West      19778.0  2023-01-01\n",
      "1     2736    Agent_2         East      10677.0  2023-01-02\n",
      "2      NaN    Agent_3        North      83710.0  2023-01-03\n",
      "3     5723    Agent_4        South          NaN  2023-01-04\n",
      "4     2977    Agent_5         West      25097.0  2023-01-05\n",
      "\n",
      "\n",
      "=== Product Catalog ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Product ID    15 non-null     object \n",
      " 1   Product Name  17 non-null     object \n",
      " 2   Category      17 non-null     object \n",
      " 3   Price         17 non-null     float64\n",
      " 4   Stock         15 non-null     object \n",
      " 5   Date          20 non-null     object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 1.1+ KB\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Product ID Product Name Category  Price Stock        Date\n",
      "0        NaN        among     keep  905.0    50  2023-11-06\n",
      "1        211     consumer     sign  362.0    51  2023-09-05\n",
      "2        434         face     late  603.0   NaN  2023-12-21\n",
      "3        NaN          own    watch  169.0    19  2023-05-10\n",
      "4        490        until      NaN    NaN    43  2023-07-06\n",
      "\n",
      "\n",
      "=== Data Device ===\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Customer Device ID  14 non-null     object\n",
      " 1   Device Type         16 non-null     object\n",
      " 2   Brand               18 non-null     object\n",
      " 3   Model               19 non-null     object\n",
      " 4   IMEI                18 non-null     object\n",
      " 5   Purchase Date       20 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.1+ KB\n",
      "\n",
      "\n",
      "\n",
      "Head:\n",
      "  Customer Device ID Device Type            Brand    Model             IMEI  \\\n",
      "0                NaN    majority     Petersen LLC  usually  728543128543128   \n",
      "1               2131        five      Ross-Ramsey    score              NaN   \n",
      "2               1624         see              NaN    small              NaN   \n",
      "3                NaN      during  Smith-Rodriguez  measure  543210987654321   \n",
      "4               2641         NaN  Valdez-Gonzalez       do  876543210987654   \n",
      "\n",
      "  Purchase Date  \n",
      "0    1984-02-06  \n",
      "1    2008-05-31  \n",
      "2    1989-01-22  \n",
      "3    2006-02-05  \n",
      "4    1982-11-04  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Daftar file dataset\n",
    "datasets = [\n",
    "    ('Data Karyawan', df_datakaryawan),\n",
    "    ('Data Customer', df_datacustomer),\n",
    "    ('Alamat Customer', df_alamatcust),\n",
    "    ('Browsing History', df_browsing),\n",
    "    ('Customer Purchase', df_custpurchase),\n",
    "    ('Customer Pulsa', df_custpulsa),\n",
    "    ('Tagihan Pelanggan', df_tagihan),\n",
    "    ('Sales Report', df_reportsales),\n",
    "    ('Product Catalog', df_productcatalog),\n",
    "    ('Data Device', df_device)\n",
    "]\n",
    "for name, df in datasets:\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Info:\")\n",
    "    df.info()\n",
    "    print(\"\\n\")\n",
    "    print(\"\\nHead:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset alamat_customer.csv:\n",
      "Customer ID\n",
      "Address Line 1\n",
      "Address Line 2\n",
      "City\n",
      "State\n",
      "Postal Code\n",
      "Country\n",
      "\n",
      "Columns in dataset browsing_history.csv:\n",
      "Customer Browsing History ID\n",
      "URL\n",
      "Timestamp\n",
      "Duration (seconds)\n",
      "\n",
      "Columns in dataset customer_isipulsa.csv:\n",
      "Customer Pulsa ID\n",
      "Phone Number Isi Pulsa\n",
      "Date\n",
      "Amount\n",
      "\n",
      "Columns in dataset customer_purchase.csv:\n",
      "Customer Purchase ID\n",
      "Product ID\n",
      "Purchase Date\n",
      "Quantity\n",
      "Price\n",
      "\n",
      "Columns in dataset data_customer.csv:\n",
      "Customer ID\n",
      "Customer Name\n",
      "Customer Email\n",
      "Customer Phone Number\n",
      "Date of Birth\n",
      "Gender\n",
      "\n",
      "Columns in dataset data_karyawan.csv:\n",
      "Employee ID\n",
      "Employee Name\n",
      "Employee Email\n",
      "Employee Phone Number\n",
      "Position\n",
      "Department\n",
      "\n",
      "Columns in dataset product_catalog.csv:\n",
      "Product ID\n",
      "Product Name\n",
      "Category\n",
      "Price\n",
      "Stock\n",
      "Date\n",
      "\n",
      "Columns in dataset report_sales.csv:\n",
      "Agent ID\n",
      "Agent Name\n",
      "Sales Region\n",
      "Total Sales\n",
      "Date\n",
      "\n",
      "Columns in dataset tagihan_pelanggan.csv:\n",
      "Tagihan Customer ID\n",
      "Invoice ID\n",
      "Invoice Date\n",
      "Due Date\n",
      "Amount\n",
      "\n",
      "Columns in dataset telkomsel_device_data.csv:\n",
      "Customer Device ID\n",
      "Device Type\n",
      "Brand\n",
      "Model\n",
      "IMEI\n",
      "Purchase Date\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path ke folder yang berisi dataset\n",
    "folder_path = 'csv datasets/'\n",
    "\n",
    "# Mendapatkan list nama file dari folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Hanya mengambil file dengan ekstensi .csv\n",
    "dataset_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Loop melalui setiap dataset\n",
    "for file in dataset_files:\n",
    "    # Path lengkap ke file\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Memuat dataset ke dalam DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Menampilkan nama-nama kolom tanpa tulisan 'Index'\n",
    "    print(f\"Columns in dataset {file}:\")\n",
    "    for column in df.columns:\n",
    "        print(column)\n",
    "    print()  # Untuk memberi jeda antar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value in dataset csv datasets/data_karyawan.csv:\n",
      "Employee ID              3\n",
      "Employee Name            0\n",
      "Employee Email           0\n",
      "Employee Phone Number    4\n",
      "Position                 0\n",
      "Department               0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/data_customer.csv:\n",
      "Customer ID              4\n",
      "Customer Name            4\n",
      "Customer Email           0\n",
      "Customer Phone Number    7\n",
      "Date of Birth            0\n",
      "Gender                   0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/alamat_customer.csv:\n",
      "Customer ID       4\n",
      "Address Line 1    4\n",
      "Address Line 2    4\n",
      "City              3\n",
      "State             0\n",
      "Postal Code       6\n",
      "Country           3\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/browsing_history.csv:\n",
      "Customer Browsing History ID    2\n",
      "URL                             2\n",
      "Timestamp                       3\n",
      "Duration (seconds)              1\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/customer_purchase.csv:\n",
      "Customer Purchase ID    5\n",
      "Product ID              4\n",
      "Purchase Date           0\n",
      "Quantity                0\n",
      "Price                   0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/customer_isipulsa.csv:\n",
      "Customer Pulsa ID         3\n",
      "Phone Number Isi Pulsa    3\n",
      "Date                      0\n",
      "Amount                    4\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/tagihan_pelanggan.csv:\n",
      "Tagihan Customer ID    4\n",
      "Invoice ID             3\n",
      "Invoice Date           2\n",
      "Due Date               2\n",
      "Amount                 1\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/report_sales.csv:\n",
      "Agent ID        4\n",
      "Agent Name      2\n",
      "Sales Region    0\n",
      "Total Sales     2\n",
      "Date            0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/product_catalog.csv:\n",
      "Product ID      5\n",
      "Product Name    3\n",
      "Category        3\n",
      "Price           3\n",
      "Stock           5\n",
      "Date            0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in dataset csv datasets/telkomsel_device_data.csv:\n",
      "Customer Device ID    6\n",
      "Device Type           4\n",
      "Brand                 2\n",
      "Model                 1\n",
      "IMEI                  2\n",
      "Purchase Date         0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mencari missing value di setiap dataset\n",
    "\n",
    "# Daftar file dataset\n",
    "dataset_files = [\n",
    "                'csv datasets/data_karyawan.csv', \n",
    "                 \"csv datasets/data_customer.csv\", \n",
    "                 \"csv datasets/alamat_customer.csv\", \n",
    "                 \"csv datasets/browsing_history.csv\", \n",
    "                 \"csv datasets/customer_purchase.csv\", \n",
    "                 \"csv datasets/customer_isipulsa.csv\", \n",
    "                 \"csv datasets/tagihan_pelanggan.csv\", \n",
    "                 \"csv datasets/report_sales.csv\", \n",
    "                 \"csv datasets/product_catalog.csv\", \n",
    "                 \"csv datasets/telkomsel_device_data.csv\"\n",
    "                 ]\n",
    "\n",
    "# Mencari missing value di setiap file\n",
    "for file in dataset_files:\n",
    "    # Membaca dataset dari file CSV\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Menghitung jumlah missing value di setiap kolom\n",
    "    missing_value = df.isnull().sum()\n",
    "    \n",
    "    # Menampilkan jumlah missing value di setiap kolom untuk file saat ini\n",
    "    print(f\"Missing value in dataset {file}:\")\n",
    "    print(missing_value)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membersihkan data berdasarkan tipe kolom yang diharapkan\n",
    "def clean_data(df, column_types):\n",
    "    # Iterasi melalui setiap kolom dan tipe data yang diharapkan\n",
    "    for column, expected_type in column_types.items():\n",
    "        # Memeriksa apakah kolom tersebut ada di DataFrame\n",
    "        if column in df.columns:\n",
    "            # Jika tipe data yang diharapkan adalah 'int64'\n",
    "            if expected_type == 'int64':\n",
    "                # Mengubah kolom menjadi tipe numerik (jika tidak bisa, maka akan menjadi NaN)\n",
    "                df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "                # Menghapus baris yang memiliki nilai NaN di kolom tersebut\n",
    "                df = df.dropna(subset=[column])\n",
    "                # Mengubah tipe data kolom menjadi 'int64'\n",
    "                df[column] = df[column].astype('int64')\n",
    "            # Jika tipe data yang diharapkan adalah 'float64'\n",
    "            elif expected_type == 'float64':\n",
    "                # Mengubah kolom menjadi tipe numerik dengan kemungkinan float (mengubah non-numerik jadi NaN)\n",
    "                df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "                # Menghapus baris yang memiliki nilai NaN di kolom tersebut\n",
    "                df = df.dropna(subset=[column])\n",
    "                # Mengubah tipe data kolom menjadi 'float64'\n",
    "                df[column] = df[column].astype('float64')\n",
    "            # Jika tipe data yang diharapkan adalah 'object'\n",
    "            elif expected_type == 'object':\n",
    "                # Mengubah tipe data kolom menjadi 'object' (biasanya untuk string atau kategori)\n",
    "                df[column] = df[column].astype('object')\n",
    "    # Mengembalikan DataFrame yang telah dibersihkan\n",
    "    return df\n",
    "\n",
    "\n",
    "# Dictionary yang mendefinisikan nama file sebagai kunci dan tipe data kolom yang diharapkan sebagai nilai\n",
    "eexpected_types = {\n",
    "    'data_karyawan.csv': {\n",
    "        'Employee ID': 'int64',\n",
    "        'Employee Name': 'object',\n",
    "        'Employee Email': 'object',\n",
    "        'Employee Phone Number': 'int64',\n",
    "        'Position': 'object',\n",
    "        'Department': 'object'\n",
    "    },\n",
    "    'data_customer.csv': {\n",
    "        'Customer ID': 'int64',\n",
    "        'Customer Name': 'object',\n",
    "        'Customer Email': 'object',\n",
    "        'Customer Phone Number': 'int64',\n",
    "        'Date of Birth': 'object',\n",
    "        'Gender': 'object'\n",
    "    },\n",
    "    'alamat_customer.csv': {\n",
    "        'Customer ID': 'int64',\n",
    "        'Address Line 1': 'object',\n",
    "        'Address Line 2': 'object',\n",
    "        'City': 'object',\n",
    "        'State': 'object',\n",
    "        'Postal Code': 'int64',\n",
    "        'Country': 'object'\n",
    "    },\n",
    "    'browsing_history.csv': {\n",
    "        'Customer Browsing History ID': 'int64',\n",
    "        'URL': 'object',\n",
    "        'Timestamp': 'object',\n",
    "        'Duration (seconds)': 'int64'\n",
    "    },\n",
    "    'customer_purchase.csv': {\n",
    "        'Customer Purchase ID': 'int64',\n",
    "        'Product ID': 'int64',\n",
    "        'Purchase Date': 'object',\n",
    "        'Quantity': 'int64',\n",
    "        'Price': 'int64'\n",
    "    },\n",
    "    'customer_isipulsa.csv': {\n",
    "        'Customer Pulsa ID': 'int64',\n",
    "        'Phone Number Isi Pulsa': 'int64',\n",
    "        'Date': 'object',\n",
    "        'Amount': 'int64'\n",
    "    },\n",
    "    'tagihan_pelanggan.csv': {\n",
    "        'Tagihan Customer ID': 'int64',\n",
    "        'Invoice ID': 'int64',\n",
    "        'Invoice Date': 'object',\n",
    "        'Due Date': 'object',\n",
    "        'Amount': 'int64'\n",
    "    },\n",
    "    'report_sales.csv': {\n",
    "        'Agent ID': 'int64',\n",
    "        'Agent Name': 'object',\n",
    "        'Sales Region': 'object',\n",
    "        'Total Sales': 'int64',\n",
    "        'Date': 'object'\n",
    "    },\n",
    "    'product_catalog.csv': {\n",
    "        'Product ID': 'int64',\n",
    "        'Product Name': 'object',\n",
    "        'Category': 'object',\n",
    "        'Price': 'int64',\n",
    "        'Stock': 'int64',\n",
    "        'Date': 'object'\n",
    "    },\n",
    "    'telkomsel_device_data.csv': {\n",
    "        'Customer Device ID': 'int64',\n",
    "        'Device Type': 'object',\n",
    "        'Brand': 'object',\n",
    "        'Model': 'object',\n",
    "        'IMEI': 'int64',\n",
    "        'Purchase Date': 'object'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value rows removed from each dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('int64')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('int64')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('int64')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('int64')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('int64')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('int64')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('int64')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype('object')\n",
      "C:\\Users\\mrafi\\AppData\\Local\\Temp\\ipykernel_15984\\972222430.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Menghapus baris dengan missing value di setiap file\n",
    "cleaned_datasets = {} # Dictionary untuk menyimpan dataset yang telah dibersihkan\n",
    "\n",
    "for file in dataset_files:\n",
    "    # Membaca dataset dari file CSV\n",
    "    df = pd.read_csv(file)\n",
    "    # Menghapus baris yang memiliki nilai kosong\n",
    "    df_cleaned = df.dropna()\n",
    "    # Membersihkan data berdasarkan tipe yang diharapkan\n",
    "    file_name = os.path.basename(file)\n",
    "    if file_name in eexpected_types:\n",
    "        df_cleaned = clean_data(df_cleaned, eexpected_types[file_name])\n",
    "    # Menyimpan DataFrame yang telah dibersihkan dalam dictionary\n",
    "    cleaned_datasets[file] = df_cleaned \n",
    "print(\"Missing value rows removed from each dataset.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value in cleaned dataset csv datasets/data_karyawan.csv:\n",
      "Employee ID              0\n",
      "Employee Name            0\n",
      "Employee Email           0\n",
      "Employee Phone Number    0\n",
      "Position                 0\n",
      "Department               0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/data_customer.csv:\n",
      "Customer ID              0\n",
      "Customer Name            0\n",
      "Customer Email           0\n",
      "Customer Phone Number    0\n",
      "Date of Birth            0\n",
      "Gender                   0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/alamat_customer.csv:\n",
      "Customer ID       0\n",
      "Address Line 1    0\n",
      "Address Line 2    0\n",
      "City              0\n",
      "State             0\n",
      "Postal Code       0\n",
      "Country           0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/browsing_history.csv:\n",
      "Customer Browsing History ID    0\n",
      "URL                             0\n",
      "Timestamp                       0\n",
      "Duration (seconds)              0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/customer_purchase.csv:\n",
      "Customer Purchase ID    0\n",
      "Product ID              0\n",
      "Purchase Date           0\n",
      "Quantity                0\n",
      "Price                   0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/customer_isipulsa.csv:\n",
      "Customer Pulsa ID         0\n",
      "Phone Number Isi Pulsa    0\n",
      "Date                      0\n",
      "Amount                    0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/tagihan_pelanggan.csv:\n",
      "Tagihan Customer ID    0\n",
      "Invoice ID             0\n",
      "Invoice Date           0\n",
      "Due Date               0\n",
      "Amount                 0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/report_sales.csv:\n",
      "Agent ID        0\n",
      "Agent Name      0\n",
      "Sales Region    0\n",
      "Total Sales     0\n",
      "Date            0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/product_catalog.csv:\n",
      "Product ID      0\n",
      "Product Name    0\n",
      "Category        0\n",
      "Price           0\n",
      "Stock           0\n",
      "Date            0\n",
      "dtype: int64\n",
      "\n",
      "Missing value in cleaned dataset csv datasets/telkomsel_device_data.csv:\n",
      "Customer Device ID    0\n",
      "Device Type           0\n",
      "Brand                 0\n",
      "Model                 0\n",
      "IMEI                  0\n",
      "Purchase Date         0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mencari ulang missing value untuk memastikan tidak ada lagi\n",
    "for file, df_cleaned in cleaned_datasets.items():\n",
    "    # Menghitung jumlah missing value di setiap kolom di DataFrame yang telah dibersihkan\n",
    "    missing_value = df_cleaned.isnull().sum()\n",
    "    # Menampilkan jumlah missing value di setiap kolom untuk DataFrame yang telah dibersihkan\n",
    "    print(f\"Missing value in cleaned dataset {file}:\")\n",
    "    print(missing_value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as Excel: saved data/data_karyawan_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/data_customer_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/alamat_customer_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/browsing_history_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/customer_purchase_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/customer_isipulsa_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/tagihan_pelanggan_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/report_sales_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/product_catalog_cleaned.xlsx\n",
      "Cleaned dataset saved as Excel: saved data/telkomsel_device_data_cleaned.xlsx\n",
      "\n",
      "All cleaned datasets have been saved.\n",
      "\n",
      "Data types of cleaned datasets:\n",
      "\n",
      "=== data_karyawan.csv ===\n",
      "Employee ID               int64\n",
      "Employee Name            object\n",
      "Employee Email           object\n",
      "Employee Phone Number     int64\n",
      "Position                 object\n",
      "Department               object\n",
      "dtype: object\n",
      "\n",
      "=== data_customer.csv ===\n",
      "Customer ID               int64\n",
      "Customer Name            object\n",
      "Customer Email           object\n",
      "Customer Phone Number     int64\n",
      "Date of Birth            object\n",
      "Gender                   object\n",
      "dtype: object\n",
      "\n",
      "=== alamat_customer.csv ===\n",
      "Customer ID        int64\n",
      "Address Line 1    object\n",
      "Address Line 2    object\n",
      "City              object\n",
      "State             object\n",
      "Postal Code        int64\n",
      "Country           object\n",
      "dtype: object\n",
      "\n",
      "=== browsing_history.csv ===\n",
      "Customer Browsing History ID     int64\n",
      "URL                             object\n",
      "Timestamp                       object\n",
      "Duration (seconds)               int64\n",
      "dtype: object\n",
      "\n",
      "=== customer_purchase.csv ===\n",
      "Customer Purchase ID     int64\n",
      "Product ID               int64\n",
      "Purchase Date           object\n",
      "Quantity                 int64\n",
      "Price                    int64\n",
      "dtype: object\n",
      "\n",
      "=== customer_isipulsa.csv ===\n",
      "Customer Pulsa ID          int64\n",
      "Phone Number Isi Pulsa     int64\n",
      "Date                      object\n",
      "Amount                     int64\n",
      "dtype: object\n",
      "\n",
      "=== tagihan_pelanggan.csv ===\n",
      "Tagihan Customer ID     int64\n",
      "Invoice ID              int64\n",
      "Invoice Date           object\n",
      "Due Date               object\n",
      "Amount                  int64\n",
      "dtype: object\n",
      "\n",
      "=== report_sales.csv ===\n",
      "Agent ID         int64\n",
      "Agent Name      object\n",
      "Sales Region    object\n",
      "Total Sales      int64\n",
      "Date            object\n",
      "dtype: object\n",
      "\n",
      "=== product_catalog.csv ===\n",
      "Product ID       int64\n",
      "Product Name    object\n",
      "Category        object\n",
      "Price            int64\n",
      "Stock            int64\n",
      "Date            object\n",
      "dtype: object\n",
      "\n",
      "=== telkomsel_device_data.csv ===\n",
      "Customer Device ID     int64\n",
      "Device Type           object\n",
      "Brand                 object\n",
      "Model                 object\n",
      "IMEI                   int64\n",
      "Purchase Date         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Path ke folder untuk menyimpan hasil\n",
    "output_folder = 'saved data/'  # Sesuaikan dengan path folder Anda\n",
    "\n",
    "# Menyimpan setiap dataset yang telah dibersihkan\n",
    "for file, df_cleaned in cleaned_datasets.items():\n",
    "    # Mendapatkan nama file tanpa path\n",
    "    file_name = os.path.basename(file)\n",
    "    # Mengganti ekstensi .csv dengan _cleaned.xlsx\n",
    "    xlsx_file_name = os.path.splitext(file_name)[0] + '_cleaned.xlsx'\n",
    "    # Path lengkap untuk file output\n",
    "    output_path = os.path.join(output_folder, xlsx_file_name)\n",
    "    \n",
    "    # Menyimpan ke Excel\n",
    "    df_cleaned.to_excel(output_path, index=False)\n",
    "    print(f\"Cleaned dataset saved as Excel: {output_path}\")\n",
    "    \n",
    "    # Jika Anda juga ingin menyimpan sebagai CSV, uncomment baris-baris berikut:\n",
    "    # csv_file_name = os.path.splitext(file_name)[0] + '_cleaned.csv'\n",
    "    # csv_output_path = os.path.join(output_folder, csv_file_name)\n",
    "    # df_cleaned.to_csv(csv_output_path, index=False)\n",
    "    # print(f\"Cleaned dataset saved as CSV: {csv_output_path}\")\n",
    "\n",
    "print(\"\\nAll cleaned datasets have been saved.\")\n",
    "\n",
    "\n",
    "# Mencetak informasi tipe data dari dataset yang telah dibersihkan\n",
    "print(\"\\nData types of cleaned datasets:\")\n",
    "\n",
    "# Iterasi melalui setiap item di dictionary `cleaned_datasets`, yang berisi nama file sebagai kunci dan DataFrame yang dibersihkan sebagai nilai\n",
    "for file, df_cleaned in cleaned_datasets.items():\n",
    "    # Mencetak nama file dataset yang sedang diproses\n",
    "    print(f\"\\n=== {os.path.basename(file)} ===\")\n",
    "    \n",
    "    # Mencetak tipe data dari setiap kolom dalam DataFrame yang dibersihkan\n",
    "    print(df_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as CSV: saved data/data_karyawan_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/data_customer_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/alamat_customer_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/browsing_history_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/customer_purchase_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/customer_isipulsa_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/tagihan_pelanggan_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/report_sales_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/product_catalog_cleaned.csv\n",
      "Cleaned dataset saved as CSV: saved data/telkomsel_device_data_cleaned.csv\n",
      "\n",
      "All cleaned datasets have been saved as CSV.\n",
      "\n",
      "Data types of cleaned datasets:\n",
      "\n",
      "=== data_karyawan.csv ===\n",
      "Employee ID               int64\n",
      "Employee Name            object\n",
      "Employee Email           object\n",
      "Employee Phone Number     int64\n",
      "Position                 object\n",
      "Department               object\n",
      "dtype: object\n",
      "\n",
      "=== data_customer.csv ===\n",
      "Customer ID               int64\n",
      "Customer Name            object\n",
      "Customer Email           object\n",
      "Customer Phone Number     int64\n",
      "Date of Birth            object\n",
      "Gender                   object\n",
      "dtype: object\n",
      "\n",
      "=== alamat_customer.csv ===\n",
      "Customer ID        int64\n",
      "Address Line 1    object\n",
      "Address Line 2    object\n",
      "City              object\n",
      "State             object\n",
      "Postal Code        int64\n",
      "Country           object\n",
      "dtype: object\n",
      "\n",
      "=== browsing_history.csv ===\n",
      "Customer Browsing History ID     int64\n",
      "URL                             object\n",
      "Timestamp                       object\n",
      "Duration (seconds)               int64\n",
      "dtype: object\n",
      "\n",
      "=== customer_purchase.csv ===\n",
      "Customer Purchase ID     int64\n",
      "Product ID               int64\n",
      "Purchase Date           object\n",
      "Quantity                 int64\n",
      "Price                    int64\n",
      "dtype: object\n",
      "\n",
      "=== customer_isipulsa.csv ===\n",
      "Customer Pulsa ID          int64\n",
      "Phone Number Isi Pulsa     int64\n",
      "Date                      object\n",
      "Amount                     int64\n",
      "dtype: object\n",
      "\n",
      "=== tagihan_pelanggan.csv ===\n",
      "Tagihan Customer ID     int64\n",
      "Invoice ID              int64\n",
      "Invoice Date           object\n",
      "Due Date               object\n",
      "Amount                  int64\n",
      "dtype: object\n",
      "\n",
      "=== report_sales.csv ===\n",
      "Agent ID         int64\n",
      "Agent Name      object\n",
      "Sales Region    object\n",
      "Total Sales      int64\n",
      "Date            object\n",
      "dtype: object\n",
      "\n",
      "=== product_catalog.csv ===\n",
      "Product ID       int64\n",
      "Product Name    object\n",
      "Category        object\n",
      "Price            int64\n",
      "Stock            int64\n",
      "Date            object\n",
      "dtype: object\n",
      "\n",
      "=== telkomsel_device_data.csv ===\n",
      "Customer Device ID     int64\n",
      "Device Type           object\n",
      "Brand                 object\n",
      "Model                 object\n",
      "IMEI                   int64\n",
      "Purchase Date         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Path ke folder untuk menyimpan hasil\n",
    "output_folder = 'saved data/'  # Sesuaikan dengan path folder Anda\n",
    "\n",
    "# Menyimpan setiap dataset yang telah dibersihkan\n",
    "for file, df_cleaned in cleaned_datasets.items():\n",
    "    # Mendapatkan nama file tanpa path\n",
    "    file_name = os.path.basename(file)\n",
    "    # Mengganti ekstensi .csv dengan _cleaned.csv\n",
    "    csv_file_name = os.path.splitext(file_name)[0] + '_cleaned.csv'\n",
    "    # Path lengkap untuk file output\n",
    "    output_path = os.path.join(output_folder, csv_file_name)\n",
    "    \n",
    "    # Menyimpan ke CSV\n",
    "    df_cleaned.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned dataset saved as CSV: {output_path}\")\n",
    "\n",
    "print(\"\\nAll cleaned datasets have been saved as CSV.\")\n",
    "\n",
    "# Mencetak informasi tipe data dari dataset yang telah dibersihkan\n",
    "print(\"\\nData types of cleaned datasets:\")\n",
    "\n",
    "# Iterasi melalui setiap item di dictionary `cleaned_datasets`, yang berisi nama file sebagai kunci dan DataFrame yang dibersihkan sebagai nilai\n",
    "for file, df_cleaned in cleaned_datasets.items():\n",
    "    # Mencetak nama file dataset yang sedang diproses\n",
    "    print(f\"\\n=== {os.path.basename(file)} ===\")\n",
    "    \n",
    "    # Mencetak tipe data dari setiap kolom dalam DataFrame yang dibersihkan\n",
    "    print(df_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil salah satu data random dari semua 10 csv, lalu dijadikan JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: data_karyawan_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Employee ID\",\n",
      "    \"value\": 7024\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Employee Name\",\n",
      "    \"value\": \"Vincent White\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Employee Email\",\n",
      "    \"value\": \"jasondawson@gonzales.com\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Employee Phone Number\",\n",
      "    \"value\": 88810234567\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Position\",\n",
      "    \"value\": \"Chiropodist\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Department\",\n",
      "    \"value\": \"Murray PLC\"\n",
      "  }\n",
      "]\n",
      "Processed file: data_customer_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer ID\",\n",
      "    \"value\": 3647\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Customer Name\",\n",
      "    \"value\": \"Barbara Campbell\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Customer Email\",\n",
      "    \"value\": \"dawsonjustin@gmail.com\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Customer Phone Number\",\n",
      "    \"value\": 89565432109\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date of Birth\",\n",
      "    \"value\": \"1987-04-25\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Gender\",\n",
      "    \"value\": \"Female\"\n",
      "  }\n",
      "]\n",
      "Processed file: alamat_customer_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer ID\",\n",
      "    \"value\": 6234\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Address Line 1\",\n",
      "    \"value\": \"0735 Cynthia Groves\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Address Line 2\",\n",
      "    \"value\": \"Apt. 139\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"City\",\n",
      "    \"value\": \"New Stephanie\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"State\",\n",
      "    \"value\": \"Texas\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Postal Code\",\n",
      "    \"value\": 74042\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Country\",\n",
      "    \"value\": \"Belarus\"\n",
      "  }\n",
      "]\n",
      "Processed file: browsing_history_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Browsing History ID\",\n",
      "    \"value\": 3934\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"URL\",\n",
      "    \"value\": \"https://www.williams.com/\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Timestamp\",\n",
      "    \"value\": \"2024-05-19 07:55:54\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Duration (seconds)\",\n",
      "    \"value\": 313\n",
      "  }\n",
      "]\n",
      "Processed file: customer_purchase_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Purchase ID\",\n",
      "    \"value\": 1083\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Product ID\",\n",
      "    \"value\": 467\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Purchase Date\",\n",
      "    \"value\": \"2024-02-04\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Quantity\",\n",
      "    \"value\": 9\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Price\",\n",
      "    \"value\": 369\n",
      "  }\n",
      "]\n",
      "Processed file: customer_isipulsa_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Pulsa ID\",\n",
      "    \"value\": 4016\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Phone Number Isi Pulsa\",\n",
      "    \"value\": 621639046263\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date\",\n",
      "    \"value\": \"2023-01-08\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Amount\",\n",
      "    \"value\": 54404\n",
      "  }\n",
      "]\n",
      "Processed file: tagihan_pelanggan_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Tagihan Customer ID\",\n",
      "    \"value\": 3113\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Invoice ID\",\n",
      "    \"value\": 2741\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Invoice Date\",\n",
      "    \"value\": \"2024-05-05\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Due Date\",\n",
      "    \"value\": \"2024-06-12\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Amount\",\n",
      "    \"value\": 3314\n",
      "  }\n",
      "]\n",
      "Processed file: report_sales_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Agent ID\",\n",
      "    \"value\": 9230\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Agent Name\",\n",
      "    \"value\": \"Agent_14\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Sales Region\",\n",
      "    \"value\": \"South\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Total Sales\",\n",
      "    \"value\": 13736\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date\",\n",
      "    \"value\": \"2023-01-14\"\n",
      "  }\n",
      "]\n",
      "Processed file: product_catalog_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Product ID\",\n",
      "    \"value\": 166\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Product Name\",\n",
      "    \"value\": \"job\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Category\",\n",
      "    \"value\": \"institution\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Price\",\n",
      "    \"value\": 32\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Stock\",\n",
      "    \"value\": 50\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date\",\n",
      "    \"value\": \"2023-11-04\"\n",
      "  }\n",
      "]\n",
      "Processed file: telkomsel_device_data_cleaned.csv\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Device ID\",\n",
      "    \"value\": 4054\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Device Type\",\n",
      "    \"value\": \"light\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Brand\",\n",
      "    \"value\": \"Scott, Holmes and Parker\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Model\",\n",
      "    \"value\": \"culture\"\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"IMEI\",\n",
      "    \"value\": 654321098765432\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Purchase Date\",\n",
      "    \"value\": \"2018-04-11\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Daftar file CSV yang akan diproses, setiap file menyimpan data yang telah dibersihkan\n",
    "csv_files = [\n",
    "    'saved data/data_karyawan_cleaned.csv',\n",
    "    'saved data/data_customer_cleaned.csv',\n",
    "    'saved data/alamat_customer_cleaned.csv',\n",
    "    'saved data/browsing_history_cleaned.csv',\n",
    "    'saved data/customer_purchase_cleaned.csv',\n",
    "    'saved data/customer_isipulsa_cleaned.csv',\n",
    "    'saved data/tagihan_pelanggan_cleaned.csv',\n",
    "    'saved data/report_sales_cleaned.csv',\n",
    "    'saved data/product_catalog_cleaned.csv',\n",
    "    'saved data/telkomsel_device_data_cleaned.csv'\n",
    "]\n",
    "\n",
    "# Menentukan direktori untuk menyimpan file JSON yang baru\n",
    "output_dir = 'random_rows'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Membuat direktori jika belum ada\n",
    "\n",
    "# Proses setiap file CSV dalam list\n",
    "for file in csv_files:\n",
    "    # Membaca file CSV ke dalam DataFrame pandas\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Memilih satu baris secara acak dari DataFrame\n",
    "    random_row = df.sample(n=1)\n",
    "\n",
    "    # Mengonversi baris yang dipilih ke format JSON\n",
    "    json_data = []\n",
    "    \n",
    "    # Iterasi melalui kolom dan nilai di baris yang dipilih\n",
    "    for column, row_value in random_row.iloc[0].items():\n",
    "        # Menambahkan nama kolom dan nilai ke dalam list `json_data` dengan tipe data yang sesuai\n",
    "        json_data.append({\n",
    "            \"column_name\": column,  # Nama kolom\n",
    "            \"value\": int(row_value) if isinstance(row_value, (np.int64, np.int32)) else  # Jika tipe data integer\n",
    "                     float(row_value) if isinstance(row_value, (np.float64, np.float32)) else  # Jika tipe data float\n",
    "                     row_value  # Jika tipe data lain (misalnya string atau objek)\n",
    "        })\n",
    "\n",
    "    # Menyimpan data JSON ke dalam file dengan nama yang sesuai\n",
    "    base_filename = os.path.splitext(os.path.basename(file))[0]  # Mendapatkan nama file tanpa ekstensi\n",
    "    with open(os.path.join(output_dir, f'{base_filename}_random.json'), 'w') as json_file:\n",
    "        # Menyimpan data dalam format JSON ke dalam file\n",
    "        json.dump(json_data, json_file, indent=2)\n",
    "\n",
    "    # Mencetak data JSON untuk setiap file yang diproses sebagai output\n",
    "    print(f\"Processed file: {os.path.basename(file)}\")\n",
    "    print(json.dumps(json_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan API OpenAI untuk mencari data pii dan non pii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: alamat_customer_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer ID\",\n",
      "    \"value\": 6234,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Address Line 1\",\n",
      "    \"value\": \"0735 Cynthia Groves\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Address Line 2\",\n",
      "    \"value\": \"Apt. 139\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"City\",\n",
      "    \"value\": \"New Stephanie\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"State\",\n",
      "    \"value\": \"Texas\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Postal Code\",\n",
      "    \"value\": 74042,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Country\",\n",
      "    \"value\": \"Belarus\",\n",
      "    \"pii_flag\": true\n",
      "  }\n",
      "]\n",
      "Processed file: browsing_history_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Browsing History ID\",\n",
      "    \"value\": 3934,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"URL\",\n",
      "    \"value\": \"https://www.williams.com/\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Timestamp\",\n",
      "    \"value\": \"2024-05-19 07:55:54\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Duration (seconds)\",\n",
      "    \"value\": 313,\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: customer_isipulsa_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Pulsa ID\",\n",
      "    \"value\": 4016,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Phone Number Isi Pulsa\",\n",
      "    \"value\": 621639046263,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date\",\n",
      "    \"value\": \"2023-01-08\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Amount\",\n",
      "    \"value\": 54404,\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: customer_purchase_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Purchase ID\",\n",
      "    \"value\": 1083,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Product ID\",\n",
      "    \"value\": 467,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Purchase Date\",\n",
      "    \"value\": \"2024-02-04\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Quantity\",\n",
      "    \"value\": 9,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Price\",\n",
      "    \"value\": 369,\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: data_customer_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer ID\",\n",
      "    \"value\": 3647,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Customer Name\",\n",
      "    \"value\": \"Barbara Campbell\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Customer Email\",\n",
      "    \"value\": \"dawsonjustin@gmail.com\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Customer Phone Number\",\n",
      "    \"value\": 89565432109,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date of Birth\",\n",
      "    \"value\": \"1987-04-25\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Gender\",\n",
      "    \"value\": \"Female\",\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: data_karyawan_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Employee ID\",\n",
      "    \"value\": 7024,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Employee Name\",\n",
      "    \"value\": \"Vincent White\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Employee Email\",\n",
      "    \"value\": \"jasondawson@gonzales.com\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Employee Phone Number\",\n",
      "    \"value\": 88810234567,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Position\",\n",
      "    \"value\": \"Chiropodist\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Department\",\n",
      "    \"value\": \"Murray PLC\",\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: product_catalog_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Product ID\",\n",
      "    \"value\": 166,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Product Name\",\n",
      "    \"value\": \"job\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Category\",\n",
      "    \"value\": \"institution\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Price\",\n",
      "    \"value\": 32,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Stock\",\n",
      "    \"value\": 50,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date\",\n",
      "    \"value\": \"2023-11-04\",\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: report_sales_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Agent ID\",\n",
      "    \"value\": 9230,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Agent Name\",\n",
      "    \"value\": \"Agent_14\",\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Sales Region\",\n",
      "    \"value\": \"South\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Total Sales\",\n",
      "    \"value\": 13736,\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Date\",\n",
      "    \"value\": \"2023-01-14\",\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: tagihan_pelanggan_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Tagihan Customer ID\",\n",
      "    \"value\": 3113,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Invoice ID\",\n",
      "    \"value\": 2741,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Invoice Date\",\n",
      "    \"value\": \"2024-05-05\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Due Date\",\n",
      "    \"value\": \"2024-06-12\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Amount\",\n",
      "    \"value\": 3314,\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n",
      "Processed file: telkomsel_device_data_cleaned_random.json\n",
      "[\n",
      "  {\n",
      "    \"column_name\": \"Customer Device ID\",\n",
      "    \"value\": 4054,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Device Type\",\n",
      "    \"value\": \"light\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Brand\",\n",
      "    \"value\": \"Scott, Holmes and Parker\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Model\",\n",
      "    \"value\": \"culture\",\n",
      "    \"pii_flag\": false\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"IMEI\",\n",
      "    \"value\": 654321098765432,\n",
      "    \"pii_flag\": true\n",
      "  },\n",
      "  {\n",
      "    \"column_name\": \"Purchase Date\",\n",
      "    \"value\": \"2018-04-11\",\n",
      "    \"pii_flag\": false\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key=\"API KEY\")  # Replace with your actual API key\n",
    "\n",
    "# Function to interact with the OpenAI chat model\n",
    "def chat_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# List of JSON files in the random_rows directory\n",
    "json_files = [\n",
    "    'random_rows/alamat_customer_cleaned_random.json',\n",
    "    'random_rows/browsing_history_cleaned_random.json',\n",
    "    'random_rows/customer_isipulsa_cleaned_random.json',\n",
    "    'random_rows/customer_purchase_cleaned_random.json',\n",
    "    'random_rows/data_customer_cleaned_random.json',\n",
    "    'random_rows/data_karyawan_cleaned_random.json',\n",
    "    'random_rows/product_catalog_cleaned_random.json',\n",
    "    'random_rows/report_sales_cleaned_random.json',\n",
    "    'random_rows/tagihan_pelanggan_cleaned_random.json',\n",
    "    'random_rows/telkomsel_device_data_cleaned_random.json'\n",
    "]\n",
    "\n",
    "# Process each JSON file\n",
    "for json_file_path in json_files:\n",
    "    # Load the random row JSON data\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    # Prepare the prompt for OpenAI API\n",
    "    columns_info = [{\"column_name\": item[\"column_name\"], \"value\": item[\"value\"]} for item in json_data]\n",
    "    prompt = (\n",
    "        f\"Given these column details: {columns_info}. \"\n",
    "        \"For each column and value, determine if it is PII. \"\n",
    "        \"Output the results as a JSON object with each column name as the key and true or false as the value for PII status.\"\n",
    "    )\n",
    "\n",
    "    # Get the PII flags using OpenAI API\n",
    "    pii_flags_text = chat_gpt(prompt)\n",
    "\n",
    "    # Attempt to parse the response to extract the PII flags\n",
    "    try:\n",
    "        pii_flags = json.loads(pii_flags_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to decode JSON for file {json_file_path}. Response was: {pii_flags_text}\")\n",
    "        continue  # Skip this file and move to the next\n",
    "\n",
    "    # Add PII flag to each column in the JSON data\n",
    "    for item in json_data:\n",
    "        column_name = item[\"column_name\"]\n",
    "        item[\"pii_flag\"] = pii_flags.get(column_name, False)\n",
    "\n",
    "    # Print the JSON data with PII flags\n",
    "    print(f\"Processed file: {os.path.basename(json_file_path)}\")\n",
    "    print(json.dumps(json_data, indent=2))\n",
    "\n",
    "    # Optionally, save the JSON data with PII flags back to a file\n",
    "    output_json_file_path = json_file_path.replace('.json', '_with_pii_flags.json')\n",
    "    with open(output_json_file_path, 'w') as output_json_file:\n",
    "        json.dump(json_data, output_json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary PII berhasil dimasukkan atau diperbarui di tabel pii_summary.\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Definisikan koneksi\n",
    "connection = pymysql.connect(\n",
    "    host='127.0.0.1',\n",
    "    user='root',  # Ganti dengan username Anda\n",
    "    password='',  # Kosongkan jika tidak menggunakan password\n",
    "    db='PII'  # Ganti dengan nama database Anda\n",
    ")\n",
    "\n",
    "def insert_or_update_pii_summary(json_files):\n",
    "    # Buat tabel untuk menyimpan summary PII jika belum ada\n",
    "    create_summary_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS pii_summary (\n",
    "        `table_name` VARCHAR(255),\n",
    "        `pii_count` INT,\n",
    "        `total_columns` INT,\n",
    "        `date` VARCHAR(10)\n",
    "    );\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(create_summary_table_query)\n",
    "        connection.commit()\n",
    "\n",
    "    for json_file in json_files:\n",
    "        # Baca file JSON\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Dapatkan nama tabel dari nama file\n",
    "        table_name = os.path.splitext(os.path.basename(json_file))[0].replace('_cleaned_random_with_pii_flags', '')\n",
    "\n",
    "        # Hitung PII Count (berapa banyak kolom yang memiliki pii_flag = true)\n",
    "        pii_count = sum(1 for item in data if item.get('pii_flag', False))\n",
    "\n",
    "        # Hitung Total Columns (total kolom dalam tabel JSON)\n",
    "        total_columns = len(data)\n",
    "\n",
    "        # Format tanggal saat ini sebagai DD-MM-YYYY\n",
    "        current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "\n",
    "        # Cek apakah ada entri untuk table_name di pii_summary\n",
    "        select_query = \"SELECT * FROM pii_summary WHERE table_name = %s;\"\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(select_query, (table_name,))\n",
    "            result = cursor.fetchone()\n",
    "\n",
    "        if result:\n",
    "            # Jika sudah ada entri, periksa apakah PII count telah berubah\n",
    "            last_pii_count = result[1]  # Nilai PII Count dari entri terakhir\n",
    "            if last_pii_count != pii_count:\n",
    "                # Jika PII count berubah, lakukan update pada baris yang ada\n",
    "                update_query = \"\"\"\n",
    "                UPDATE pii_summary \n",
    "                SET pii_count = %s, total_columns = %s, `date` = %s \n",
    "                WHERE table_name = %s;\n",
    "                \"\"\"\n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.execute(update_query, (pii_count, total_columns, current_date, table_name))\n",
    "                    connection.commit()\n",
    "        else:\n",
    "            # Jika belum ada entri, masukkan data baru\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO pii_summary (`table_name`, `pii_count`, `total_columns`, `date`) \n",
    "            VALUES (%s, %s, %s, %s);\n",
    "            \"\"\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(insert_query, (table_name, pii_count, total_columns, current_date))\n",
    "                connection.commit()\n",
    "\n",
    "    print(\"Summary PII berhasil dimasukkan atau diperbarui di tabel pii_summary.\")\n",
    "\n",
    "# Daftar file JSON\n",
    "json_files = [\n",
    "    'random_rows/alamat_customer_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/browsing_history_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/customer_isipulsa_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/customer_purchase_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/data_customer_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/data_karyawan_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/product_catalog_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/report_sales_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/tagihan_pelanggan_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/telkomsel_device_data_cleaned_random_with_pii_flags.json'\n",
    "]\n",
    "\n",
    "# Masukkan atau perbarui summary PII ke tabel\n",
    "insert_or_update_pii_summary(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detail PII berhasil dimasukkan atau diperbarui di tabel pii_details.\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Definisikan koneksi\n",
    "connection = pymysql.connect(\n",
    "    host='127.0.0.1',\n",
    "    user='root',  # Ganti dengan username Anda\n",
    "    password='',  # Kosongkan jika tidak menggunakan password\n",
    "    db='PII'  # Ganti dengan nama database Anda\n",
    ")\n",
    "\n",
    "def insert_or_update_pii_details(json_files):\n",
    "    # Buat tabel untuk menyimpan detail PII jika belum ada\n",
    "    create_details_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS pii_details (\n",
    "        `table_name` VARCHAR(255),\n",
    "        `column_name` VARCHAR(255),\n",
    "        `pii_flag` BOOLEAN\n",
    "    );\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(create_details_table_query)\n",
    "        connection.commit()\n",
    "\n",
    "    for json_file in json_files:\n",
    "        # Baca file JSON\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Dapatkan nama tabel dari nama file\n",
    "        table_name = os.path.splitext(os.path.basename(json_file))[0].replace('_cleaned_random_with_pii_flags', '')\n",
    "\n",
    "        for item in data:\n",
    "            column_name = item.get('column_name')\n",
    "            pii_flag = 1 if item.get('pii_flag', False) else 0  # Boolean diubah ke 1 atau 0\n",
    "\n",
    "            # Cek apakah entri sudah ada untuk kombinasi `table_name` dan `column_name`\n",
    "            select_query = \"\"\"\n",
    "            SELECT * FROM pii_details WHERE table_name = %s AND column_name = %s;\n",
    "            \"\"\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(select_query, (table_name, column_name))\n",
    "                result = cursor.fetchone()\n",
    "\n",
    "            if result:\n",
    "                # Jika sudah ada, update nilai pii_flag\n",
    "                update_query = \"\"\"\n",
    "                UPDATE pii_details \n",
    "                SET pii_flag = %s \n",
    "                WHERE table_name = %s AND column_name = %s;\n",
    "                \"\"\"\n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.execute(update_query, (pii_flag, table_name, column_name))\n",
    "                    connection.commit()\n",
    "            else:\n",
    "                # Jika belum ada, masukkan baris baru\n",
    "                insert_query = \"\"\"\n",
    "                INSERT INTO pii_details (`table_name`, `column_name`, `pii_flag`) \n",
    "                VALUES (%s, %s, %s);\n",
    "                \"\"\"\n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.execute(insert_query, (table_name, column_name, pii_flag))\n",
    "                    connection.commit()\n",
    "\n",
    "    print(\"Detail PII berhasil dimasukkan atau diperbarui di tabel pii_details.\")\n",
    "\n",
    "# Daftar file JSON\n",
    "json_files = [\n",
    "    'random_rows/alamat_customer_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/browsing_history_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/customer_isipulsa_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/customer_purchase_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/data_customer_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/data_karyawan_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/product_catalog_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/report_sales_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/tagihan_pelanggan_cleaned_random_with_pii_flags.json',\n",
    "    'random_rows/telkomsel_device_data_cleaned_random_with_pii_flags.json'\n",
    "]\n",
    "\n",
    "# Masukkan atau perbarui detail PII ke tabel\n",
    "insert_or_update_pii_details(json_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
